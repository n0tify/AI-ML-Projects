 Decision Trees and Random Forests - Heart Disease Classification
âœ… Objective:
To build and evaluate tree-based models (Decision Tree and Random Forest) to classify whether a patient has heart disease or not.

ğŸ› ï¸ Tools Used:
Python

Scikit-learn

Pandas

Matplotlib

Seaborn

Graphviz (for tree visualization, optional)

ğŸ“‚ Dataset:
Dataset Name: Heart Disease UCI Dataset

Source: Kaggle

Link: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction

Target Variable: target (1 = Disease, 0 = No Disease)

âœ… Project Highlights:
ğŸ¯ Tasks Performed:
Loaded and explored the dataset.

Checked target class distribution.

Preprocessed features (if needed).

Split data into train-test sets.

Trained a Decision Tree Classifier (max depth = 4).

Visualized the decision tree.

Trained a Random Forest Classifier (100 trees, max depth = 6).

Evaluated and compared both models.

Analyzed feature importance for Random Forest.

Saved all relevant visualizations.

âœ… Model Performance:
Model	Accuracy
Decision Tree	~0.8390
Random Forest	~0.8511

âœ… Visualizations Included:
ğŸ¨ Target Class Distribution (target_class_distribution.png)

ğŸ¨ Decision Tree Visualization (decision_tree_plot.png)

ğŸ¨ Random Forest Feature Importance (random_forest_feature_importance.png)

âœ… Interview Level Learnings:
How decision trees work

Concept of entropy & information gain

Overfitting in decision trees and pruning (via max depth)

Why Random Forest reduces overfitting (bagging technique)

Feature importance interpretation

Model evaluation using Accuracy, Precision, Recall, F1 Score

âœ… Folder Structure:
Decision Trees and Random Forests/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ heart.csv
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ decision_tree_random_forest.ipynb
â”œâ”€â”€ visuals/
â”‚   â”œâ”€â”€ target_class_distribution.png
â”‚   â”œâ”€â”€ decision_tree_plot.png
â”‚   â””â”€â”€ random_forest_feature_importance.png
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
